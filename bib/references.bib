
@article{Roth2022Towards,
  abstract = {Being able to spot defective parts is a critical component in large-scale industrial manufacturing. A particular challenge that we address in this work is the cold-start problem: fit a model using nominal (non-defective) example images only. While handcrafted solutions per class are possible, the goal is to build systems that work well simultaneously on many different tasks automatically. The best performing approaches combine embeddings from ImageNet models with an outlier detection model. In this paper, we extend on this line of work and propose PatchCore, which uses a maximally representative memory bank of nominal patch-features. PatchCore offers competitive inference times while achieving state-of-the-art performance for both detection and localization. On the challenging, widely used MVTec AD benchmark PatchCore achieves an image-level anomaly detection AUROC score of up to 99.6%, more than halving the error compared to the next best competitor. We further report competitive results on two additional datasets and also find competitive results in the few samples regime. Code: github.com/amazon-research/patchcore-inspection.},
  author = {Roth, Karsten and Pemula, Latha and Zepeda, Joaquin and Sch√∂lkopf, Bernhard and Brox, Thomas and Gehler, Peter},
  doi = {https://doi.org/10.1109/cvpr42600.2020.00424},
  journal = {Journal of Industrial Anomaly Detection},
  series = {CVPR},
  keywords = {type:anomaly_detection, deep_learning, ImageNet, outlier_detection, PatchCore},
  publisher = {IEEE},
  title = {Towards Total Recall in Industrial Anomaly Detection},
  url = {https://arxiv.org/pdf/2106.08265v2},
  year = {2022}
}



@article{rudolph2021same,
  abstract = {The detection of manufacturing errors is crucial in fabrication processes to ensure product quality and safety standards. Since many defects occur very rarely and their characteristics are mostly unknown a priori, their detection is still an open research question. To this end, we propose DifferNet: It leverages the descriptiveness of features extracted by convolutional neural networks to estimate their density using normalizing flows. Normalizing flows are well-suited to deal with low dimensional data distributions. However, they struggle with the high dimensionality of images. Therefore, we employ a multi-scale feature extractor which enables the normalizing flow to assign meaningful likelihoods to the images. Based on these likelihoods we develop a scoring function that indicates defects. Moreover, propagating the score back to the image enables pixel-wise localization. To achieve a high robustness and performance we exploit multiple transformations in training and evaluation. In contrast to most other methods, ours does not require a large number of training samples and performs well with as low as 16 images. We demonstrate the superior performance over existing approaches on the challenging and newly proposed MVTec AD and Magnetic Tile Defects datasets.
},
  title={Same same but differnet: Semi-supervised defect detection with normalizing flows},
  keywords={type:Training;Location awareness;Fabrication;Magnetic resonance imaging;Feature extraction;Robustness;Product design},
  author={Rudolph, Marco and Wandt, Bastian and Rosenhahn, Bodo},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={1907--1916},
  journal      = {CVRR},
  series = {CVPR},
  publisher = {IEEE},
  volume       = {abs/2008.12577},
  url={https://arxiv.org/abs/2008.12577},
  doi={https://doi.org/10.1109/WACV48630.2021.00195},
  year={2021}
}

@article{defard2021padim,
  abstract = {We present a new framework for Patch Distribution Modeling, PaDiM, to concurrently detect and localize anomalies in images in a one-class learning setting. PaDiM makes use of a pretrained convolutional neural network (CNN) for patch embedding, and of multivariate Gaussian distributions to get a probabilistic representation of the normal class. It also exploits correlations between the different semantic levels of CNN to better localize anomalies. PaDiM outperforms current state-of-the-art approaches for both anomaly detection and localization on the MVTec AD and STC datasets. To match real-world visual industrial inspection, we extend the evaluation protocol to assess performance of anomaly localization algorithms on non-aligned dataset. The state-of-the-art performance and low complexity of PaDiM make it a good candidate for many industrial applications.},
  author       = {Thomas Defard and
                  Aleksandr Setkov and
                  Angelique Loesch and
                  Romaric Audigier},
  title        = {PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection
                  and Localization},
  series = {ICPR},
  keywords={type:Computer Science;Computer Vision and Pattern Recognition},
  volume       = {abs/2011.08785},
  year         = {2020},
  url          = {https://arxiv.org/abs/2011.08785},
  doi       = {https://doi.org/10.1007/978-3-030-68799-1_35},
}


@article{li2021cutpaste,
  abstract={We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-theart 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.},
  title={Cutpaste: Self-supervised learning for anomaly detection and localization},
  author={Li, Chun-Liang and Sohn, Kihyuk and Yoon, Jinsung and Pfister, Tomas},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  keywords={type:Location awareness;Training;Computer vision;Buildings;Transfer learning;Training data;Detectors},
  pages={9664--9674},
  series = {CVPR},
  doi={https://doi.org/10.1109/CVPR46437.2021.00954},
  url={https://arxiv.org/abs/2104.04015},
  year={2021}
}

@article{gudovskiy2022cflow,
  abstract={Unsupervised anomaly detection with localization has many practical applications when labeling is infeasible and, moreover, when anomaly examples are completely missing in the train data. While recently proposed models for such data setup achieve high accuracy metrics, their complexity is a limiting factor for real-time processing. In this paper, we propose a real-time model and analytically derive its relationship to prior methods. Our CFLOW-AD model is based on a conditional normalizing flow framework adopted for anomaly detection with localization. In particular, CFLOW-AD consists of a discriminatively pretrained encoder followed by a multi-scale generative decoders where the latter explicitly estimate likelihood of the encoded features. Our approach results in a computationally and memory-efficient model: CFLOW-AD is faster and smaller by a factor of 10x than prior state-of-the-art with the same input setting. Our experiments on the MVTec dataset show that CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by 1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source our code with fully reproducible experiments.},
  title={Cflow-ad: Real-time unsupervised anomaly detection with localization via conditional normalizing flows},
  author={Gudovskiy, Denis and Ishizaka, Shun and Kozuka, Kazuki},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={98--107},
  keywords={type:Location awareness;Analytical models;Computational modeling;Feature extraction;Real-time systems;Data models;Complexity theory;Industrial Inspection Object Detection;Recognition;Categorization;Security;Surveillance;Segmentation;Grouping and Shape;Transfer;Few-shot;Semi- and Un- supervised Learning},
  series = {WACV},
  journal      = {CVRR},
  doi={https://doi.org/10.1109/WACV51458.2022.00188},
  url={https://arxiv.org/abs/2107.12571},
  year={2022}
}

@article{zavrtanik2021draem,
  abstract={Visual surface anomaly detection aims to detect local image regions that significantly deviate from normal appearance. Recent surface anomaly detection methods rely on generative models to accurately reconstruct the normal areas and to fail on anomalies. These methods are trained only on anomaly-free images, and often require hand-crafted post-processing steps to localize the anomalies, which prohibits optimizing the feature extraction for maximal detection capability. In addition to reconstructive approach, we cast surface anomaly detection primarily as a discriminative problem and propose a discriminatively trained reconstruction anomaly embedding model (DRAEM). The proposed method learns a joint representation of an anomalous image and its anomaly-free reconstruction, while simultaneously learning a decision boundary between normal and anomalous examples. The method enables direct anomaly localization without the need for additional complicated post-processing of the network output and can be trained using simple and general anomaly simulations. On the challenging MVTec anomaly detection dataset, DRAEM outperforms the current state-of-the-art unsupervised methods by a large margin and even delivers detection performance close to the fully-supervised methods on the widely used DAGM surface-defect detection dataset, while substantially outperforming them in localization accuracy.},
  title={Draem-a discriminatively trained reconstruction embedding for surface anomaly detection},
  author={Zavrtanik, Vitjan and Kristan, Matej and Sko{\v{c}}aj, Danijel},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8330--8339},
  keywords={type:Location awareness;Surface reconstruction;Computer vision;Computational modeling;Feature extraction;Task analysis;Image reconstruction;Transfer;Unsupervised Learning;Recognition and classification;Vision applications and systems},
  series = {CVPR},
  volume       = {abs/2108.07610},
  doi={https://doi.org/10.1109/ICCV48922.2021.00822},
  url={https://arxiv.org/abs/2108.07610},
  year={2021}
}



@article{deng2022anomaly,
  abstract={Knowledge distillation (KD) achieves promising results on the challenging problem of unsupervised anomaly detection (AD). The representation discrepancy of anomalies in the teacher-student (TS) model provides essential evidence for AD. However, using similar or identical architectures to build the teacher and student models in previous studies hinders the diversity of anomalous representations. To tackle this problem, we propose a novel TS model consisting of a teacher encoder and a student decoder and introduce a simple yet effective" reverse distillation" paradigm accordingly. Instead of receiving raw images directly, the student network takes teacher model's one-class embedding as input and targets to restore the teacher's multi-scale representations. Inherently, knowledge distillation in this study starts from abstract, high-level presentations to low-level features. In addition, we introduce a trainable one-class bottleneck embedding (OCBE) module in our TS model. The obtained compact embedding effectively preserves essential information on normal patterns, but abandons anomaly perturbations. Extensive experimentation on AD and one-class novelty detection benchmarks shows that our method surpasses SOTA performance, demonstrating our proposed approach's effectiveness and generalizability.},
  title={Anomaly detection via reverse distillation from one-class embedding},
  author={Deng, Hanqiu and Li, Xingyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9737--9746},
  series = {CVPR},
  keywords={type:Location awareness;Computer vision;Perturbation methods;Computational modeling;Computer architecture;Pattern recognition;Image restoration;Self-& semi-& meta- Representation learning; Transfer;low-shot;long-tail learning},
  journal      = {CVRR},
  volume       = {abs/2201.10703},
  url={https://arxiv.org/abs/2201.10703},
  doi={https://doi.org/10.1109/CVPR52688.2022.00951},
  year={2022}
}

@article{salehi2021multiresolution,
  abstract={Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the" distillation" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks' intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert's knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.},
  title={Multiresolution knowledge distillation for anomaly detection},
  author={Salehi, Mohammadreza and Sadjadi, Niousha and Baselizadeh, Soroosh and Rohban, Mohammad H and Rabiee, Hamid R},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14902--14912},
  keywords={type:Training;Location awareness;Knowledge engineering;Computer vision;Image resolution;Pattern recognition;Task analysis},
  series = {CVPR},
  journal      = {CVRR},
  volume       = {abs/2011.11108},
  url={https://arxiv.org/pdf/2011.11108},
  doi={https://doi.org/10.1109/CVPR46437.2021.01466},
  year={2021}
}

@article{yi2020patch,
  abstract={In this paper, we address the problem of image anomaly detection and segmentation. Anomaly detection involves making a binary decision as to whether an input image contains an anomaly, and anomaly segmentation aims to locate the anomaly on the pixel level. Support vector data description (SVDD) is a long-standing algorithm used for an anomaly detection, and we extend its deep learning variant to the patch-based method using self-supervised learning. This extension enables anomaly segmentation and improves detection performance. As a result, anomaly detection and segmentation performances measured in AUROC on MVTec AD dataset increased by 9.8% and 7.0%, respectively, compared to the previous state-of-the-art methods. Our results indicate the efficacy of the proposed method and its potential for industrial application. Detailed analysis of the proposed method offers insights regarding its behavior, and the code is available online.},
  title={Patch svdd: Patch-level svdd for anomaly detection and segmentation},
  author={Yi, Jihun and Yoon, Sungroh},
  booktitle={Proceedings of the Asian conference on computer vision},
  series = {ACCV},
  volume       = {abs/2006.16067},
  keywords={type:Computer Science;Computer Vision and Pattern Recognition},
  url          = {https://arxiv.org/abs/2006.16067},
  doi={https://doi.org/10.1007/978-3-030-69544-6_23},
  year={2020}
}

@article{bergmann2020uninformed,
  abstract={We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.},
  title={Uninformed students: Student-teacher anomaly detection with discriminative latent embeddings},
  author={Bergmann, Paul and Fauser, Michael and Sattlegger, David and Steger, Carsten},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={4183--4192},
  keywords={type:Anomaly detection;Training;Feature extraction;Image segmentation;Training data;Machine learning;Uncertainty},
  series = {CVPR},
  volume       = {abs/1911.02357},
  url          = {http://arxiv.org/abs/1911.02357},
  doi={https://doi.org/10.1109/cvpr42600.2020.00424},
  year={2020}
}